Software Engineering relies on the existence of good test-suites to ensure quality of produced artifacts, and various coverage criteria are used to measure how well a test suite performs.
These criteria include statement coverage, branch coverage, and path coverage.

Another approach to judging test suite quality is to generate mutant versions of the program, and measure the effectiveness of test suite in distinguishing these mutants.
This method is called mutation analysis.

It is often assumed that since path coverage subsumes branch coverage, and branch coverage subsumes statement coverage in adequate test suites, the same relationship holds for their efficacy in finding defects.
Previous research suggests that mutation score of a test suite has a high correlation with quality of a test suite.
However, as mutation analysis is a computationally intensive task, various alternatives to it have been explored in the past.
A few studies have suggested branch coverage as an approximation to mutation coverage.
However, the applicability of these studies have been some what limited due to the handful of sample programs that these studies were based on.

We analyze the data from a much larger number of real world projects, and find that statement coverage is the best predictor for quality of test suite.
We further cross validate our result by comparing it with test suite generated randomly, which agrees our findings.
Finally, we suggest a hypothesis as to why this result is not surpricing given the nature of coverage techniques.
We also note a surpricing observation that line coverage approximates path coverage better than branch coverage.
