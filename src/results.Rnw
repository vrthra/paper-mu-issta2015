\section{Results}
\label{sec:results}

Our results for x\% sampling over program elements are given
in Table~\ref{tbl:xselsample}. The result of its variation, using
\textit{round(sample)} is given in Table~\ref{tbl:xselround}. The result
of using \textit{ceil(sample)} is given in Table~\ref{tbl:xselceil}.
The first column in each table provides the scope of sampling i.e if it was
done per class, per method, per line etc. The second column provides the
fraction involved.  Third column contains the $R^2$ value obtained between
the mutation score of the sampling criteria used and the full mutation score.
The fourth column contains the mutant reduction factor. This is the average of
total mutants produced divided by the number of mutants sampled by the criteria.
Fifth column contains the standard deviation of the same. A few of the projects
did not return any value for certain sampling criterias for particular mutation
reduction fractions. The sixth column contains the number of projects that
actually had valid values for the criteria being considered. The seventh column
is the average multiplier between the sampled mutation score and the full mutation
score.


\subsection{Standard deviation of mutant reduction}
We observe multiple patterns in our results. First, for all sampling criterias used, standard deviation of reduction of mutants is roughly proportional to their mean value. This can be seen in Figure~\ref{fig:roundsel}. Secondly, we also observe that standard deviation based on project sampling is lower than standard deviation of class based sampling for corresponding mean mutant reduction, and the standard deviation of class based sampling is lower than that based on methods, and similarly for lines.

The first observation from our different kinds of random sampling is that the standard deviation tends to increase with the increase in mutation reduction. While this in itself is not unexpected, what is unexpected is the difference in the increase in standard deviation between different kinds of sampling techniques. Our observations suggests that random sampling based on the entire project has a much lower growth of standard deviation (and hence higher stability of results) than sampling in lower scopes. Further, we also observe that the rate of increase in standard deviation actually increases as we go into more finer scopes such as class, method and line, with line having the largest increase in standard deviation.

Further, looking at the reduction of mutants in Figure~\ref{fig:fullimgshape} and Figure~\ref{fig:fullimgsize}, we see that the x\% selection strategy is generally the best strategy, and it is generally best to stick with random selection from the entire project. This too is perhaps not unexpected, since sampling from the entire population rather than its elements should provide a better correlation with the final score.

Our analysis of results suggests that different kinds of operator selection criterias can actually provide better reduction in mutants while not reducing the approximatin accuracy below acceptable limits.

\subsection{SDL vs Random selection}
\begin{figure*}[t]
<<sdl.x,fig.width=10, fig.height=10, out.width='.95\\linewidth', out.heigth='4in', echo=F, message=F, warn=F,fig.lp="fig:">>=
par(mfrow=c(2,2))
with(o.pit.all, plot(all.cov~TSDL.cov, pch='+', main='Original SDL'))
with(o.pit.all, plot(all.cov~l.1x1_per_line.cov, pch='+', main='Original 1 per line'))
with(r.pit.all, plot(all.cov~TSDL.cov, pch='+', main='Randoop SDl'))
with(r.pit.all, plot(all.cov~l.1x1_per_line.cov, pch='+', main='Randoop 1 per line'))
@
\label{fig:sdl1}
\caption{Statement Deletion vs One per line.}
\end{figure*}
<<results='asis'>>=
oprand <- subset(stats.df,!grepl('^..op', rownames(stats.df)))

oprand.x <- subset(oprand,grepl('^.1x[0-9]+_per_', operator))
oprand.l <- subset(oprand,!grepl('^.1x[0-9]+_per_', operator))
@
