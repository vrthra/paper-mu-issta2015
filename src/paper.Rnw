\newcommand*\per{\scalebox{.5}{\%}}
\newcommand\Mua{Mutation analysis~}
\newcommand\mua{mutation analysis~}
\begin{comment}
<<setup, include=FALSE, cache=FALSE, message=FALSE, echo=FALSE>>=
#options(warn=-1)
options(digits=3)
opts_chunk$set(fig.path='figure/twocolumn-', fig.align='center', fig.show='hold', echo=FALSE)
render_listings()
logit<-function(x) log(x/(1-x))
@
<<chunk-hook, echo=2>>=
<<setup>>
@
\end{comment}


<<a,message=F, echo=F>>=
require(xtable)
require(data.table)
load('data/mu.rda')
@

% 10 pages for the main text + 1 for references.
\section{Introduction}
% 1. Describe the problem
% 2. State your contributions

Mutation analysis originally proposed by Lipton\cite{lipton1971fault} involves systematic transformation of program through introduction of first order syntactical changes\cite{ammann2008introduction}. Researchers have shown that the mutations thus introduced behave similarly to the real faults\cite{andrews2005mutation}, and hence can be used as a stand-in for real faults when determining the efficacy of a test suite against faults.

While mutation analysis provides a useful metric, its use has been held back due to its high computational requirements\cite{jia2011analysis}. This has led researchers to search for ways of reducing the resource requirements of the analysis.
The methods in this direction can be classified into ``Do faster'', ``Do fewer'', and ``Do smarter''\cite{offutt2001mutation}. The ``Do fewer'' approach has come in for special study, and various researchers have investigated different ways to reduce the number of mutants thus produced.

One of the main approaches is selective mutation, proposed by Mathur\cite{mathur1991performance}, and further refined by Offutt et al.\cite{offutt1993anexperimental}. This approach relies on the fact that some of the mutagens generate a large number of variants, and hence produce highly redundant test cases. Previous research suggested that elimination of mutagens with high fertility results in the reduction of total number of mutations produced, and hence reduces the computational requirements.

% TODO check the survey again on selective mutation.

It was recently questioned whether this approach indeed resulted in a tangible improvement over random selection of mutants\cite{zhang2010operator}, which did not find operator based selection to be better than random selection. It was later found that using operator based selection and random sampling was better than using each strategy separately\cite{zhang2013ase}.

Another research, initially by Unch\cite{untch2009onreduced} and recently by Deng et al.\cite{deng2013empirical} suggests using software deletion operator since it produces the least number of mutants (smallest neighborhood). The researchers were able to obtain a close approximation of original mutant score with significant savings with this approach.

However, our previous research suggests that mutation coverage is closely predicted by statement coverage, this suggests that any criteria that forces accounting of the impact of each statement should provide a close approximation to the full mutation score. Hence, our research suggests that SDL works because it forces accounting of each line, and a random sampling criteria that provides the same criteria should result in similar results.

In our analysis, we find that a random sampling approach that randomly chose a single mutant per line was found to have a better correlation with the full mutation score than that obtained by SDL. Further it was also found that the mutation score produced by random sampling was closer to the full mutation score than that produced by SDL.

\section{Related Work}
Mathur\cite{mathur1991performance, wong1993mutation, wong1995reducing} first mentioned the idea of constrained mutation in a one-pager. This was taken up by Offut et al.\cite{offutt1993experimental}. (Offutt states in his 1993 paper\cite{offutt1993experimental} that Mathur has in 1991\cite{mathur1991performance} suggested the constrined/selective mutation. However, that paper does not propose it at all. It says we are experimenting with an idea, and that is it. It is in 1995\cite{wong1995reducing} that the idea is actually proposed, notably after Offutt has written about its effectiveness. $\ddot\smile$ - time travel?). The idea is that normal mutation has quadratic complexity on variable references while eliminatng the most fecund mutagens (SVR and ASR) achieves linear complexity on program size, while still approximating the full mutation score closely. They propose N-selective mutation which avoids N most fertile mutagens. Wong \cite{wong1995reducing} compares the effect of x\% mutation selection, and abs/ror constrained mutation. According to Wong, this is different from selective mutation in that only the most fecund operators are included rather than excluded. He finds that there is no evidence to suggest one over the other. Offutt\cite{offutt1993experimental} does not compare the effectivenss of selective mutation with x\% mutation. He also defines the concept of {\it operator strength} for an operator, which is defined as the total number of mutants that are killed by test data that is generated to kill only the mutants generated by that operator. He further posits that the mutagens with greatest strength may be the most useful ones. %(test data generated to eliminate variants of one operator may remove the mutants of other kinds too.)
This is taken up later by Mresa\cite{mresa1999efficiency} et al. who used the cost of detection of mutants as a means of selection, and uses it to define another set of operators (san, aor, sdl, ror, uoi). They also find that if very high mutation score close to 100\% is required, x\% selective mutation is better than operator selection, and conversely for less stringent scores, operator selection would be better if const of mutant is considered.

Barbosa et. al.\cite{barbosa2001toward} provides a set of guidelines for selecting mutagens.

Namin et al.\cite{namin2006finding,siami2008sufficient} treats the operator selection as a variable reduction problem, and applying statistical approaches, finds 28 operators from a total of 108 operators that are sufficient for an adequate test suite.

Offutt\cite{offutt1996anexperimental} following the previous paper\cite{offutt1993experimental} compares the effectiveness of selecting different operators. He divides the total operators into operand, operation, and statement categories, with es-selective avoiding operands, rs-selective avoiding operations, and re-selective avoiding statements, and e-selective only operations. He finds that using only operation based mutation operators (numbering 5) is sufficient for close approximation of full mutation score. He suggests that the reason they are effective is that most statements contain operators. He further posits that another reason is the amount of semantic change accomplished by an operator, and perhaps the most interesting ones are those that produce the smallest semantic difference.
% Replacement of Operand , Statement modification, Expression Modification: modify operators, ES-selective : not using operand, RS-Selective: not using expression, RE-Selective: not uinsg statement, E-selective : only expression..

Unch\cite{untch2009onreduced} suggested using a single mutagen statement deletion. He compares the statement deletion with other selective mutagen sets, and finds statement deletion operator to provide the best prediction of original mutation score ($R^2 = 0.97$)
This was carried forward by Deng et al\cite{deng2013empirical}, (according to whom, random sampling was weak when it was made low enough for appreciable mutant savings). They realize a mean mutation score of 92\% for adequate test suites with SDL alone, and generating a saving of 81\% in the number of mutants, and 41\% fewer equivalent mutants.

Zhang et al.\cite{zhang2010operator}, compares operator based mutant selection to random mutant selection. They compare three diffrent operator based selection techniques from Offutt et al., Barbosa et al., and Namin et al. against random mutant selection, with equal mutant probability, and equal mutagen probaiblity. They find that none of these selection techniques are superior to random selection, with same number of mutants. They also find that equal mutation sampling is more effective for larger subjects compared to equal mutagen sampling and the reverse is true for smaller subjects.
A second paper by Zhang et al.\cite{zhang2013ase} investigates 8 sampling strategies on top of operator based mutant selection. They find that sampling strategies based on programming elements (method based) performed best.
% Baseline : x\% from selected set
% MOP : x\% from each mutagen
% for these, it is sampled from operator based selected set.
% PLEm : x\% from inside the same program element.
% PLE + MOP: sample x\% from same mutagen from same element.

% On Mutation and Dataflow : W.E Eong
Wong et al~\cite{wong1994on} suggests random sampling of mutants from the complete population.

Wong and Mathur suggests constrained mutation~\cite{} which chooses specific mutation operators only.

% Empirical Evaluation of the Statement Deletion Mutation Operator : Offutt
Deng et al~\cite{deng2013empirical} considers the effect of using a single mutation operator -- the statement deletion operator. They define deletion for different language elements,

\section{Methodology}
We collected a random sample of Java programs from Github\cite{github} that utilized the Maven\cite{maven} system for building. Next, we selected those programs from this set that passed all the unit test cases within them. We ran mutation analysis on this set of projects using PIT\cite{pitest}, with the mutators selected set to {\it all}. Because of the limitations of using a bytecode mutation engine, we could not implement statement deletion directly. Instead, we made use of the following mutation operators, that closely approximated statement deletion operator -- remove void method calls, remove non void method calls, remove conditionals, remove member variable assignments, remove increments and decrements. Finally, we modified the mutation engine to only choose one random mutation per line out of the set of applicable mutants for that line. For the second phase, we looked at the ratio between the number of mutants produced by the set of operators corresponding to statement deletion, and that of the random line mutants, and used this as a probability to add the mutants for the random line set. This was done to ensure that the results from the random sampling and statement deletion could be compared.

\section{Analysis}

<<prepare,echo=F>>=
attach(m)
sdl_f <- mut.avg~sdl.mut.avg + 0
rnd_f <- mut.avg~lrnd.mut.avg + 0

sdl_all <- lm(sdl_f)
rnd_all <- lm(rnd_f)

sdl_s <- summary(sdl_all)
rnd_s <- summary(rnd_all)

sdl.est <- sdl_s$coefficients['sdl.mut.avg','Estimate']
rnd.est <- rnd_s$coefficients['lrnd.mut.avg','Estimate']

sdl.r <- sdl_s$r.squared
rnd.r <- rnd_s$r.squared

@

\begin{figure*}[t]
<<plots, fig.width=5, fig.height=5, out.width='.45\\linewidth', out.heigth='4in', echo=F, message=F, warn=F,fig.lp="fig:">>=
plot(sdl_f, main='SDL ~ ALL',pch='*')
abline(sdl_all, col='red')
plot(rnd_f, main='RND ~ ALL',pch='*')
abline(rnd_all, col='blue')
abline(sdl_all, col='red', lty=2)
@
\caption{Plots}
\label{fig:caddrm}
\end{figure*}


\begin{figure*}[t]
<<mutnum, fig.width=5, fig.height=5, out.width='.45\\linewidth', out.heigth='4in', echo=F, message=F, warn=F,fig.lp="fig:">>=
hist(log(10,m$sdl.pit.mutation.total), breaks=50, col=rgb(0,0,1,1/4), main='histogram of log(sdl) mutation score')
hist(log(10,m$sdl.pit.mutation.num), breaks=50, add=T, col=rgb(1,0,0,1/4))

hist(log(10,m$lrnd.pit.mutation.total), breaks=50, col=rgb(0,0,1,1/4), main='histogram of log(rnd) mutation score')
hist(log(10,m$lrnd.pit.mutation.num), breaks=50, add=T, col=rgb(1,0,0,1/4))

hist(log(10,m$pit.mutation.total), breaks=50, col=rgb(0,0,1,1/4), main='histogram of log(total) mutation score')
hist(log(10,m$pit.mutation.num), breaks=50, add=T, col=rgb(1,0,0,1/4))
@
\caption{Plots of total mutation number, and those killed.}
\label{fig:caddrm}
\end{figure*}


\subsection{Correlation Analysis}

$ \mu\{ M_{all}| M_{sample} \} = 0 + \beta_1 \times M{sample}  $

The interesting part is (1) the $\beta_1$ coefficient which tells how much we must multiply the  sampled/selected score to get original score, and $R^2$ which tells us how close the score is.

\subsubsection{sdl.mut.avg and mut.avg}

<<>>=
c <- cor(subset(m, select=c(sdl.mut.avg, mut.avg)) , method="kendall", use="pairwise")['sdl.mut.avg', 'mut.avg']
d <- cor(subset(m, select=c(lrnd.mut.avg, mut.avg)) , method="kendall", use="pairwise")['lrnd.mut.avg', 'mut.avg']
@

$ \mu_\{M_{all} | M_{sdl}\} = \Sexpr{sdl.est} \times M_{sdl} \text{ : } R^2 = \Sexpr{sdl.r} \text{,} \tau_{\beta} = \Sexpr{c}$

\subsubsection{lrnd.mut.avg and mut.avg}

$ \mu_\{M_{all} | M_{rnd}\} = \Sexpr{rnd.est} \times M_{rnd} \text{ : } R^2 = \Sexpr{rnd.r} \text{,} \tau_{\beta} = \Sexpr{d}$

\subsection{Regression Analysis}
The next question we will tackle is if there exist a difference at all between SDL mutagen and the random sampling. We can perform two statistical tests to answer this question. For the first, we run a simple paired t-test.

<<>>=
s <- t.test(lrnd.mut.avg, sdl.mut.avg, paired=T)
@

The paired t-test failed to sufficient difference between the two distributions with a two-sided p-value of \Sexpr{s$p.value}. That is, we do not have sufficient evidence to conclude that the two distributions are different.

The second approch is convoluted (I am a little unclear here.). We try to predict the original mutation score using the mutation score from both sdl and random sampling.
Our full model is

$ \mu_\{M_{all} | M_{sdl}, M_{rnd}\} = 0 + \beta_1 {sdl} + \beta_2 M_{rnd} + \beta_3 M_{sdl} M_{rnd}  $
\begin{small}
<<results='asis'>>=
s <- subset(m, select=c(mut.avg,sdl.mut.avg))
s$type <- 'sdl'
colnames(s) <- c('mut', 'sample', 'type')
r <- subset(m, select=c(mut.avg,lrnd.mut.avg))
r$type <- 'rnd'
colnames(r) <- c('mut', 'sample', 'type')
all <- rbind(s, r)
fm <- with(all, lm(mut ~ sample + type + sample:type))
sm <- anova(fm)
print(xtable(sm,caption="My caption"), size="\\small")
@
\end{small}

We see that both type and sample:type are non-significant for predicting the final model, and sequentially removing them does not change the effectiveness. Hence, the techniques random sampling and statement deletion operator do not have any difference.

\begin{figure*}[t]
<<tplots, fig.width=5, fig.height=5, out.width='.45\\linewidth', out.heigth='4in', echo=F, message=F, warn=F,fig.lp="fig:">>=
t_f <- sdl.time~lrnd.time
plot(t_f, main='SDL ~ RND',pch='*')
abline(lm(t_f), col='red')
detach(m)
@
\caption{Time}
\label{fig:caddrm}
\end{figure*}



\section{Results}

We see from the data that random sampling has a higher $R^2$, and also approximates the all  mutations score better.
However, caveat emptor. There is a difference between the number of mutators for SDL and RAND. If our approximation was right, we should have gotten nearly same number of mutators. However
The number of mutators in RND is
 \Sexpr{sum(m$lrnd.pit.mutation.total) / sum(m$sdl.pit.mutation.total)} times SDL.

The total mutants for all is \Sexpr{sum(m$pit.mutation.total)}, for rnd is \Sexpr{sum(m$lrnd.pit.mutation.total)} and for sdl is \Sexpr{sum(m$sdl.pit.mutation.total)}

\begin{enumerate}
\item [TODO] We should check if the distribution significantly different too.
\item [TODO] Use sampling
\item [TODO] Check on randoop samples too
\item [TODO] Implement bomb (athrow) and see its mutation score, and see how close it comes.
\item [TODO] Compare random selection with class, method, and mutagen sampling.
\item [TODO] Report time for each, as cost.
\item [TODO] Find the mutant count to LOC multiplier, and use it to get the probability of choosing for each project.
\end{enumerate}
