\section{Introduction}

% 1. Describe the problem % 2. State your contributions
Mutation analysis is a method for evaluating the quality of test suites. It
involves producing a family of \emph{mutants}, programs with small differences
from the original program, and evaluating the effectiveness of test suites
against these mutants~\cite{lipton1971fault, ammann2008introduction}. Studies
by Andrews et al.~\cite{andrews2005mutation,andrews2006using} and more recently
by Just et al.~\cite{just2014mutants} suggest
that mutations can simulate behavior of real faults and can resemble mutants.
However, mutation
analysis of test suites has not sufficiently permeated software engineering
practice~\cite{daka2014asurvey} even though the need for a tool that is
able to evaluate tests based on their fault finding quality is keenly
felt~\cite{runeson2006asurvey}.

An impediment to the wider adoption of mutation analysis is its high
computational cost.  The set of simple mutants for even a moderate sized
program can be very large, making mutation analysis prohibitively time
consuming.

A major strain of research into cost-reduction of mutation
analysis is to choose a smaller, representative set of
mutants~\cite{offutt2001mutation,jia2011analysis} --- often called the
\textit{do fewer} approach. This approach can be generally divided into
selective strategies and sampling strategies.

Selective mutation strategies attempt to select a representative
subset of mutation \emph{operators} based on heuristics and
statistical analysis, and apply this subset of operators to
generate mutants instead of applying the whole set of mutation
operators~\cite{offutt1993anexperimental,untch2009onreduced}.

Sampling strategies seek to randomly select a set of representative
mutants.  This was investigated first by Acree~\cite{acree1980mutation}
and Budd~\cite{budd1980mutation}, who proposed using only a small fraction of
randomly selected mutants.  Wong and Mathur found that random sampling fraction
as low as 10\% could provide accurate results~\cite{jia2011analysis}. It was
recently found that the fraction required to achieve adequacy on mutation
sampling increases at a rate of $O(x^{\frac{1}{4}})$ when program size
increases linearly~\cite{zhang2014empirical}.

Recent studies~\cite{zhang2010icse,zhang2013ase} investigating the relative
merits of random sampling strategies and operator selection suggests that
random sampling can perform as well as or better than operator selection, and
a strategy of either sampling based on program elements or one combining both
program element-based sampling and operator selection was the best approach.

However, as pointed out by Zhang et al.~\cite{zhang2013ase}, the field has
a serious lacuna in large scale research, both in the size of the programs
studied, and in the number and diversity of programs, which reduces our
confidence in the result of studies have been done so far. The lack of 
extensive validation using an extensive variety of subjects is the case for all
studies including selective mutation studies, sampling studies, and
also hybrid approaches. This is particularly worrisome if mutation analysis
is to gain wider acceptance among testing professionals.

We also note that quite a few of the influential
studies~\cite{offutt1993experimental,offutt1996anexperimental,wong1995reducing,mresa1999efficiency}
were conducted on older programming languages such as Fortran, with operators
specific to the language, and may not directly applicable to newer languages
such as Java.

Finally, with bytecode-based ~\footnote{A \textit{do faster} approach for eliminating
the compilation step to gain execution speed} mutation engines such as
PIT~\cite{pitest} and Javalanche~\cite{schuler2009efficient} becoming common in both
development and research (e.g. \cite{zhang2013ase}, \cite{gopinath2014code},
and \cite{inozemtseva2014coverage}), operators based on source code
modification are no longer directly applicable, and their equivalents in
bytecode need to be identified and compared with other approaches.

This paper studies different mutant selection strategies on large number
of Java programs using a popular bytecode-based mutation PIT.  We sampled
$312$ opensource Java project between $50$ to $100K$ non-comment lines of
code (excluding test cases) from Github and Apache Foundation. This set
of projects include many of popular Java projects that are regularly used
in literature (such as Apache Common Lang, Common Math and Joda Time). For
the mutation analysis of this study, we choose PIT, a fast and easy to use
mutation analysis tool for Java, which has been used by researchers in the
past~\cite{gopinath2014code,inozemtseva2014coverage} for its wide range
of operators. In total, this study involves 1,885,306 mutants and
76096 JUnit test cases with 144926 asserts.

For this study, we experimented five classic mutation selection
techniques: Constrained \cite{wong1995reducing}, E-Selective
\cite{offutt1996anexperimental}, Javalanche \cite{schuler2009efficient},
Variable Reduction~\cite{namin2006finding} and N-Selection
\cite{offutt1993experimental}, along with two sampling approaches:
element based \cite{zhang2013ase} and operator based sampling
\cite{wong1995reducing}. We compare test effectiveness of each of techniques
with pure random sampling. Our results show that in most cases there is no
statistically significant benefit for mutation selection techniques. Moreover,
in cases with statistically significant benefit, the gain is so low that is
essentially negligible.

Given a set of mutants and a universe of test cases, we can approximate the
minimal set of test cases required to kill those mutants.\footnote{We only
approximate this, with greedy methods, due to the high cost of computing a
perfect minimal set, as established in the test case selection literature
\cite{yoo2012regression}.}  Ideally, we would like a set of mutants that
require as many test cases as possible, if we assume that the original
set of test cases is populated with useful, non-redundant test cases.
While the suites of many open source programs are far from adequate,
they should satisfy that requirement:  each test was almost always added
by considerable manual labor, and was at least believed to be useful.
Therefore, any tests omitted likely indicate a potential to miss faults.
A good mutation selection strategy, therefore, should 1) be as close to the
original set of mutants as possible, in terms of the test cases it requires
in a minimal suite and 2) require more test cases than a randomly selected
set of mutants of the same size.

All test cases are not created equal, of course -- we use assertion counts
and execution time as other measures.

This suggests that an easy way to evaluate a mutation reduction strategy
would be to see if it promotes such test suites; that is, either test suites
with a large number of non-redundant test cases, or those with a large number
of asserts.

If we assume that testers would prefer adding test cases that increases the
mutation score, then a good strategy should reward the behavior of adding
non-redundant test cases and test suites with larger number of asserts.
Thus it should choose a set of mutants that are killed by a larger number
of such non-redundant tests at-least in comparison with random selection
of the same number of mutants as the chosen set. We could also ensure that
a reduction strategy does not miss out on important tests by running the
set of non-redundant tests against the full set of mutants to see how many
of the mutants were detected in comparison with the original number of
detected mutants~\footnote{This is defined as the operator mutation score
by Mresa et al.~\cite{mresa1999efficiency}. But the term mutation score is
already a popular synonym for the mutation fraction detected. We call it the
strategy effectiveness in this paper}. This can again be compared to the test
cases selected by a random sample of same number of mutants to see if the
strategy performed better at-least with respect to random sampling. Since
this evaluation criteria does not depend on the mutation-adequacy of the
test suite under consideration, we can run the evaluation using real world
projects which almost always have non-adequate test suites.

\noindent\textbf{Contributions.} The specific contributions of this paper are:
\begin{itemize}
\item Our study is the largest so far in terms of both the size of programs
involved ($50$ to $100,000$ lines excluding tests), and the number of
programs analyzed ($312$ unique open source projects) for mutant reduction
strategies. This allows for stronger and more widely applicable conclusions
about effectiveness.

\item We compare a much larger number of mutant reduction strategies
than previous studies. Our reduction strategies include all the common
and influential strategies for random sampling, element scoped sampling,
operator based sampling, and operator selection, that have been proposed in
previous studies.

\item Our evaluation criteria is applicable to non-adequate test suites
which makes the results immediately relevant for real world programs with
non-adequate test suites.

\item Most importantly, we find that current operator reduction strategies
seldom perform better than random sampling of mutants, which suggests a need
for further research in this area.

\end{itemize}

\noindent\textbf{Organization.} Section~\ref{sec:related} describes the
research in mutation reduction strategies. Section~\ref{sec:methodology}
 discusses the sampling and operator
selection strategies we study in detail. The analysis is given in
Section~\ref{sec:analysis}, and the results of experiments are detailed in
Section~\ref{sec:results}. Section ~\ref{sec:conclusion} concludes the paper.

