\section{Introduction}

% 1. Describe the problem % 2. State your contributions
Mutation analysis is a method for evaluating the quality of test suites. It
involves producing a family of \emph{mutants}, programs with small
differences from the original program, and evaluating the
effectiveness of test suites against these
mutants~\cite{lipton1971fault, ammann2008introduction}. Research by
Andrews et. al~\cite{andrews2005mutation} suggest that mutations can
simulate behavior of real faults.
% thus
% introduced behave in a fashion similar to real faults, with respect to
% the difficulty of detection.

An impediment to the wider adoption of mutation analysis is its
high computational cost.  The set of simple mutants for even a
moderate sized program can be very large, making mutation
analysis prohibitively time consuming.

A major strain of research into cost-reduction of mutation analysis is
to choose a smaller, representative set of
mutants~\cite{offutt2001mutation,jia2011analysis} --- often called the
\textit{do fewer} approach. This approach can be generally divided
into selective strategies and sampling strategies.

Selective mutation strategies attempt to select a representative
subset of mutation \emph{operators} based on heuristics and
statistical analysis, and apply this subset of operators to generate
mutants instead of applying the whole set of mutation
operators~\cite{offutt1993anexperimental,untch2009onreduced}.
%Recent work suggests that using statement deletion alone can
%be an effective approach~\cite{untch2009onreduced}.

Sampling strategies seek to randomly select a set of representative
mutants.  This was investigated first by
Acree~\cite{acree1980mutation} and Budd~\cite{budd1980mutation}, who
proposed using only a small fraction of randomly selected mutants.
Wong and Mathur found that random sampling fraction as low as 10\%
could provide accurate results~\cite{jia2011analysis}, and was recently
found that it increases at a rate of $O(x^{\frac{1}{4}})$ when program
size increases linearly~\cite{zhang2014empirical}.

Recent work~\cite{zhang2010icse,zhang2013ase} investigating the
relative merits of random sampling strategies and operator selection
suggests that random sampling can perform as well as or better than operator
selection, and a strategy of either sampling based on program elements or
one combining both program element-based sampling and operator selection
was the best approach.

However, as pointed out by Zhang et al.~\cite{zhang2013ase}, the field
has a serious lacuna in large scale research, both in the size of the
programs studied, and in the number and diversity of programs, which
reduces our confidence. This is true for selective mutation studies,
sampling studies, and also for comparatively newer studies that attempt
to combine methods. This is particularly worrisome if mutation analysis
is to gain wider acceptance among testing professionals.

Further, quite a few of the influential studies~\cite{offutt1993experimental,offutt1996anexperimental,wong1995reducing,mresa1999efficiency}
were conducted on older programming languages such as Fortran, with
operators specific to the language, and are not directly applicable to
newer languages such as Java.

Finally, with bytecode~\footnote{
A \textit{do faster} approach for eliminating
the compilation step to gain execution speed
} based mutation
engines like PIT~\cite{pitest} and Javalanche~\cite{javalanche}
, operators based on
source code modification are no longer applicable, and their
equivalents in bytecode need to be identified and compared with other
approaches. A detailed discussion of these issues can be found in
Section~\ref{sec:related}.


We have attempted to rectify this situation with a large scale study of real
world programs. As detailed in Section~\ref{sec:methodology}, we sample
$312$ Java programs from Github, with size ranging from $50$ to $100,000$
lines (excluding tests), allowing us to draw more widely applicable
statistical inferences.

% For a mutation selection strategy to be considered effective, especially during
% the development, it should be able to expose as many defect-like behaviors as
% possible.

% Alex: added
Given a set of mutants and a universe of test cases, we can approximate the
minimal set of test cases required to kill those mutants.\footnote{We only
approximate this, with greedy methods, due to the high cost of computing a
perfect minimal set, as established in the test case selection literature
\cite{yoo2012regression}.}  Ideally, we would like a set of mutants that require
as many test cases as possible, if we assume that the original set of test
cases is populated with useful, non-redundant test cases.  While the suites
of many open source programs are far from adequate, they should satisfy that
requirement:  each test was almost always added by considerable manual labor,
and was at least believed to be useful.  Therefore, any tests omitted likely
indicate a potential to miss faults.  A good mutation selection strategy,
therefore, should 1) be as close to the original set of mutants as possible,
in terms of the test cases it requires in a minimal suite and 2) require
more test cases than a randomly selected set of mutants of the same size.

All test cases are not created equal, of course -- we use assertion counts
and execution time as other measures.

% Alex: rm
% Consider any test in a test suite. It is written with the intent of
% checking for the absence of some (faulty) behavior. From the perspective of a
% a tester, the best testsuite is one that checks for the absence
% of the largest number of faulty behaviors. If tests were equivalent in the
% amount of behaviors that they verify, then the best testsuite would be one that
% encouraged adding the largest number of non-redundant test cases. However,
% it is possible that different tests are not equivalent in the number of
% behaviors that they check. We can approximate this to some extent by
% including the number of assert statements within each test~\footnote{We
% approximate the effect of exception-only test cases by starting the assert
% count from $1$ rather than $0$}.

Hence an easy way to evaluate a mutation reduction strategy would be to
see if it promotes such test suites; that is, either test suites with a large
number of non-redundant test cases, or those with a large number of asserts.

If we assume that testers would prefer adding test cases that increases the
mutation score, then a good strategy should reward the behavior of adding
non-redundant test cases and test suites with larger number of asserts.
Thus it should choose a set of mutants that are killed by a larger number
of such non-redundant tests at-least in comparison with random selection
of the same number of mutants as the chosen set. We could also ensure that
a reduction strategy does not miss out on important tests by running the
set of non-redundant tests against the full set of mutants to see how many
of the mutants were detected in comparison with the original number of
detected mutants. This can again be compared to the test cases selected by
a random sample of same number of mutants to see if the strategy performed
better at-least with respect to random sampling. Since this evaluation crtieria
does not depend on the mutation-adequacy of the test suite under consideration,
we can run the evaluation using real world projects which almost always have
non-adequate test suites.

Section~\ref{sec:related} describes the research in mutation reduction 
strategies. Section~\ref{sec:methodology} discusses the sampling and
operator
selection strategies we study in detail. The analysis is given in
Section~\ref{sec:analysis}, and the results of our
experiment are given in Section~\ref{sec:results}, followed by
detailed discussion of what these results imply in Section
~\ref{sec:discussion}. The specific contributions of this paper are:

\begin{itemize}

\item Our study is the largest so far in terms of
both the size of programs involved ($50$ to $100,000$ lines excluding tests),
and the number of programs analyzed ($312$ unique open source projects) for
mutant reduction strategies. This allows for stronger and more widely
applicable conclusions about effectiveness.

\item We compare a much larger
number of mutant reduction strategies than previous studies. Our reduction
strategies include all the common and influential strategies for
random sampling, element scoped sampling, operator based sampling,
and operator selection, that have been proposed in previous studeies.

\item Our evaluation crtieria is applicable to non-adequate test suites
which makes the results immediately relevant for real world programs with
non-adequate test suites.

\item Most importantly, we find that current operator reduction strategies
seldom perform better than random sampling of mutants, which suggests a need
for further research in this area.

\end{itemize}

